{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>6.1. Exploring the Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this project, we're going to work with data from the Survey of Consumer Finances (SCF). The SCF is a survey sponsored by the US Federal Reserve. It tracks financial, demographic, and opinion information about families in the United States. The survey is conducted every three years, and we'll work with an extract of the results from 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/missoy/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prepare Data</h2>\n",
    "<h3>Import</3>\n",
    "\n",
    "First, we need to load the data, which is stored in a compressed CSV file: SCFP2019.csv.gz. In the last project, you learned how to decompress files using gzip and the command line. However, pandas read_csv function can work with compressed files directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 6.1.1</h2>Read the file \"data/SCFP2019.csv.gz\" into the DataFrame df.\n",
    "\n",
    "Read a CSV file into a DataFrame using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/SCFP2019.csv.gz')\n",
    "print(\"df type:\", type(df))\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things you might notice here is that this dataset is HUGE — over 20,000 rows and 351 columns! SO MUCH DATA!!! We won't have time to explore all of the features in this dataset, but you can look in the data dictionary for this project for details and links to the official Code Book. For now, let's just say that this dataset tracks all sorts of behaviors relating to the ways households earn, save, and spend money in the United States.\n",
    "\n",
    "For this project, we're going to focus on households that have \"been turned down for credit or feared being denied credit in the past 5 years.\" These households are identified in the \"TURNFEAR\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.2:** Use amask to subset create df to only households that have been turned down or feared being turned down for credit (\"TURNFEAR\" == 1). Assign this subset to the variable name df_fear.\n",
    "\n",
    "Subset a DataFrame with a mask using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['TURNFEAR'] == 1\n",
    "df_fear = df[mask]\n",
    "print(\"df_fear type:\", type(df_fear))\n",
    "print(\"df_fear shape:\", df_fear.shape)\n",
    "df_fear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Explore</h3>\n",
    "<h4>Age<h4>\n",
    "Now that we have our subset, let's explore the characteristics of this group. One of the features is age group (\"AGECL\").</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.3:** Create a list age_groups with the unique values in the \"AGECL\" column. Then review the entry for \"AGECL\" in the Code Book to determine what the values represent.\n",
    "\n",
    "Determine the unique values in a column using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_groups = df['AGECL'].unique()\n",
    "print(\"Age Groups:\", age_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age Groups: [6 3 1 5 4 2]\n",
    "Looking at the Code Book we can see that \"AGECL\" represents categorical data, even though the values in the column are numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simplifies data storage, but it's not very human-readable. So before we create a visualization, let's create a version of this column that uses the actual group names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.4:** Create a Series agecl that contains the observations from \"AGECL\" using the true group names.\n",
    "\n",
    "Create a Series in pandas.\n",
    "Replace values in a column using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agecl_dict = {\n",
    "    1: \"Under 35\",\n",
    "    2: \"35-44\",\n",
    "    3: \"45-54\",\n",
    "    4: \"55-64\",\n",
    "    5: \"65-74\",\n",
    "    6: \"75 or Older\",\n",
    "}\n",
    "\n",
    "age_cl = df_fear['AGECL'].replace(agecl_dict)\n",
    "print(\"age_cl type:\", type(age_cl))\n",
    "print(\"age_cl shape:\", age_cl.shape)\n",
    "age_cl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.5:** Create a bar chart showing the value counts from age_cl. Be sure to label the x-axis \"Age Group\", the y-axis \"Frequency (count)\", and use the title \"Credit Fearful: Age Groups\".\n",
    "\n",
    "Create a bar chart using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cl_value_counts = age_cl.value_counts()\n",
    "\n",
    "# Bar plot of `age_cl_value_counts`\n",
    "age_cl_value_counts.plot(\n",
    "    kind='bar',\n",
    "    xlabel='Age Group',\n",
    "    ylabel='Frequency (count)',\n",
    "    title='Credit Fearful: Age Groups'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that by creating their own age groups, the authors of the survey have basically made a histogram for us comprised of 6 bins. Our chart is telling us that many of the people who fear being denied credit are younger. But the first two age groups cover a wider range than the other four. So it might be useful to look inside those values to get a more granular understanding of the data.\n",
    "\n",
    "To do that, we'll need to look at a different variable: \"AGE\". Whereas \"AGECL\" was a categorical variable, \"AGE\" is continuous, so we can use it to make a histogram of our own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.6:** Create a histogram of the \"AGE\" column with 10 bins. Be sure to label the x-axis \"Age\", the y-axis \"Frequency (count)\", and use the title \"Credit Fearful: Age Distribution\".\n",
    "\n",
    "Create a histogram using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of \"AGE\"\n",
    "df_fear['AGE'].hist(bins=10)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Credit Fearful: AGE GROUP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like younger people are still more concerned about being able to secure a loan than older people, but the people who are most concerned seem to be between 30 and 40.\n",
    "\n",
    "<h2>Race</h2>\n",
    "\n",
    "Now that we have an understanding of how age relates to our outcome of interest, let's try some other possibilities, starting with race. If we look at the Code Book for \"RACE\", we can see that there are 4 categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there's no 4 category here. If a value for 4 did exist, it would be reasonable to assign it to \"Asian American / Pacific Islander\" — a group that doesn't seem to be represented in the dataset. This is a strange omission, but you'll often find that large public datasets have these sorts of issues. The important thing is to always read the data dictionary carefully. In this case, remember that this dataset doesn't provide a complete picture of race in America — something that you'd have to explain to anyone interested in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.7:** Create a horizontal bar chart showing the normalized value counts for \"RACE\". In your chart, you should replace the numerical values with the true group names. Be sure to label the x-axis \"Frequency (%)\", the y-axis \"Race\", and use the title \"Credit Fearful: Racial Groups\". Finally, set the xlim for this plot to (0,1).\n",
    "\n",
    "Create a bar chart using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dict = {\n",
    "    1: \"White/Non-Hispanic\",\n",
    "    2: \"Black/African-American\",\n",
    "    3: \"Hispanic\",\n",
    "    5: \"Other\",\n",
    "}\n",
    "\n",
    "race = df_fear['RACE'].replace(race_dict)\n",
    "race_value_counts = race.value_counts(normalize=True)\n",
    "print(race_value_counts)\n",
    "# Create bar chart of race_value_counts\n",
    "race_value_counts.plot(kind='barh')\n",
    "plt.xlim((0, 1))\n",
    "plt.xlabel(\"Frequency (%)\")\n",
    "plt.ylabel(\"Race\")\n",
    "plt.title(\"Credit Fearful: Racial Groups\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that White/Non-Hispanic people worry more about being denied credit, but thinking critically about what we're seeing, that might be because there are more White/Non-Hispanic in the population of the United States than there are other racial groups, and the sample for this survey was specifically drawn to be representative of the population as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.8:** Recreate the horizontal bar chart you just made, but this time use the entire dataset df instead of the subset df_fear. The title of this plot should be \"SCF Respondents: Racial Groups\"\n",
    "\n",
    "- Create a bar chart using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dict = {\n",
    "    1: \"White/Non-Hispanic\",\n",
    "    2: \"Black/African-American\",\n",
    "    3: \"Hispanic\",\n",
    "    5: \"Other\",\n",
    "}\n",
    "race = df['RACE'].replace(race_dict)\n",
    "race_value_counts = race.value_counts(normalize=True)\n",
    "# Create bar chart of race_value_counts\n",
    "race_value_counts.plot(kind='barh')\n",
    "plt.xlim((0, 1))\n",
    "plt.xlabel(\"Frequency (%)\")\n",
    "plt.ylabel(\"Race\")\n",
    "plt.title(\"SCF Respondents: Racial Groups\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this second bar chart change our perception of the first one? On the one hand, we can see that White Non-Hispanics account for around 70% of whole dataset, but only 54% of credit fearful respondents. On the other hand, Black and Hispanic respondents represent 23% of the whole dataset but 40% of credit fearful respondents. In other words, Black and Hispanic households are actually more likely to be in the credit fearful group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.9:** Create a DataFrame df_inccat that shows the normalized frequency for income categories for both the credit fearful and non-credit fearful households in the dataset. Your final DataFrame should look something like this:\n",
    "\n",
    "    TURNFEAR   INCCAT  frequency</br>\n",
    "0            0     90-100       0.297296</br>\n",
    "1            0    60-79.9       0.174841</br>\n",
    "2            0    40-59.9     0.143146</br>\n",
    "3            0       0-20     0.140343</br>\n",
    "4            0    21-39.9     0.135933</br>\n",
    "5            0    80-89.9     0.108441</br>\n",
    "6            1       0-20     0.288125</br>\n",
    "7            1    21-39.9     0.256327</br>\n",
    "8            1    40-59.9     0.228856</br>\n",
    "9            1    60-79.9     0.132598</br>\n",
    "10           1     90-100     0.048886</br>\n",
    "11           1    80-89.9     0.045209</br>\n",
    "- Aggregate data in a Series using value_counts in pandas.\n",
    "- Aggregate data using the groupby method in pandas.\n",
    "- Create a Series in pandas.\n",
    "- Rename a Series in pandas.\n",
    "- Replace values in a column using pandas.\n",
    "- Set and reset the index of a DataFrame in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inccat_dict = {\n",
    "    1: \"0-20\",\n",
    "    2: \"21-39.9\",\n",
    "    3: \"40-59.9\",\n",
    "    4: \"60-79.9\",\n",
    "    5: \"80-89.9\",\n",
    "    6: \"90-100\",\n",
    "}\n",
    "\n",
    "df_inccat = (\n",
    "    df['INCCAT']\n",
    "    .replace(inccat_dict)\n",
    "    .groupby(df['TURNFEAR'])\n",
    "    .value_counts(normalize=True)\n",
    "    .rename('Frequency')\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"df_inccat type:\", type(df_inccat))\n",
    "print(\"df_inccat shape:\", df_inccat.shape)\n",
    "df_inccat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.10:** Using seaborn, create a side-by-side bar chart of df_inccat. Set hue to \"TURNFEAR\", and make sure that the income categories are in the correct order along the x-axis. Label to the x-axis \"Income Category\", the y-axis \"Frequency (%)\", and use the title \"Income Distribution: Credit Fearful vs. Non-fearful\".\n",
    "\n",
    "- Create a bar chart using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart of `df_inccat`\n",
    "sns.barplot(\n",
    "    x='INCCAT',\n",
    "    y='Frequency',\n",
    "    hue='TURNFEAR',\n",
    "    data=df_inccat,\n",
    "    order=inccat_dict.values()\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Income Category\")\n",
    "plt.ylabel(\"Frequency (%)\")\n",
    "plt.title(\"Income Distribution: Credit Fearful vs. Non-fearful\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the income categories across the fearful and non-fearful groups, we can see that credit fearful households are much more common in the lower income categories. In other words, the credit fearful have lower incomes.</br>\n",
    "\n",
    "So, based on all this, what do we know? Among the people who responded that they were indeed worried about being approved for credit after having been denied in the past five years, a plurality of the young and low-income had the highest number of respondents. That makes sense, right? Young people tend to make less money and rely more heavily on credit to get their lives off the ground, so having been denied credit makes them more anxious about the future.\n",
    "\n",
    "<h2>Assets</h2>\n",
    "Not all the data is demographic, though. If you were working for a bank, you would probably care less about how old the people are, and more about their ability to carry more debt. If we were going to build a model for that, we'd want to establish some relationships among the variables, and making some correlation matrices is a good place to start.\n",
    "</br>\n",
    "First, let's zoom out a little bit. We've been looking at only the people who answered \"yes\" when the survey asked about \"TURNFEAR\", but what if we looked at everyone instead? To begin with, let's bring in a clear dataset and run a single correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.11:** Calculate the correlation coefficient for \"ASSET\" and \"HOUSES\" in the whole dataset df.\n",
    "\n",
    "- Calculate the correlation coefficient for two Series using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_house_corr = df['ASSET'].corr(df['HOUSES'])\n",
    "print(\"SCF: Asset Houses Correlation:\", asset_house_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a moderate positive correlation, which we would probably expect, right? For many Americans, the value of their primary residence makes up most of the value of their total assets. What about the people in our `TURNFEAR` subset, though? Let's run that correlation to see if there's a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.12:** Calculate the correlation coefficient for \"ASSET\" and \"HOUSES\" in the whole credit-fearful subset df_fear.\n",
    "\n",
    "- Calculate the correlation coefficient for two Series using pandas.WQU WorldQuant University Applied Data Science Lab QQQQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_house_corr = df_fear['ASSET'].corr(df['HOUSES'])\n",
    "print(\"Credit Fearful: Asset Houses Correlation:\", asset_house_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! They're different! It's still only a moderate positive correlation, but the relationship between the total value of assets and the value of the primary residence is stronger for our TURNFEAR group than it is for the population as a whole.\n",
    "\n",
    "Let's make correlation matrices using the rest of the data for both df and df_fear and see if the differences persist. Here, we'll look at only 5 features: \"ASSET\", \"HOUSES\", \"INCOME\", \"DEBT\", and \"EDUC\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.13:** Make a correlation matrix using df, considering only the columns \"ASSET\", \"HOUSES\", \"INCOME\", \"DEBT\", and \"EDUC\".\n",
    "\n",
    "- Create a correlation matrix in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"ASSET\", \"HOUSES\", \"INCOME\", \"DEBT\", \"EDUC\"]\n",
    "corr = df[cols].corr()\n",
    "corr.head()\n",
    "corr.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.14:** Make a correlation matrix using df_fear.\n",
    "\n",
    "- Create a correlation matrix in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_fear[cols].corr()\n",
    "corr.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! There are some pretty important differences here! The relationship between \"DEBT\" and \"HOUSES\" is positive for both datasets, but while the coefficient for df is fairly weak at 0.26, the same number for df_fear is 0.96.\n",
    "\n",
    "Remember, the closer a correlation coefficient is to 1.0, the more exactly they correspond. In this case, that means the value of the primary residence and the total debt held by the household is getting pretty close to being the same. This suggests that the main source of debt being carried by our \"TURNFEAR\" folks is their primary residence, which, again, is an intuitive finding.\n",
    "\n",
    "\"DEBT\" and \"ASSET\" share a similarly striking difference, as do \"EDUC\" and \"DEBT\" which, while not as extreme a contrast as the other, is still big enough to catch the interest of our hypothetical banker.\n",
    "\n",
    "Let's make some visualizations to show these relationships graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart of `df_inccat`\n",
    "sns.barplot(\n",
    "    x='INCCAT',\n",
    "    y='Frequency',\n",
    "    hue='TURNFEAR',\n",
    "    data=df_inccat,\n",
    "    order=inccat_dict.values()\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Income Category\")\n",
    "plt.ylabel(\"Frequency (%)\")\n",
    "plt.title(\"Income Distribution: Credit Fearful vs. Non-fearful\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6.1.15: Create a DataFrame df_educ that shows the normalized frequency for education categories for both the credit fearful and non-credit fearful households in the dataset. This will be similar in format to df_inccat, but focus on education. Note that you don't need to replace the numerical values in \"EDUC\" with the true labels.\n",
    "\n",
    "    TURNFEAR  EDUC  frequency</br>\n",
    "0 -           0 -     12 -    0.257481</br>\n",
    "1 -           0 -      8 -    0.192029</br>\n",
    "2 -           0 -     13 -    0.149823</br>\n",
    "3  -          0 -      9 -    0.129833</br>\n",
    "4 -           0 -     14 -    0.096117</br>\n",
    "5 -           0 -     10 -    0.051150</br>\n",
    "...</br>\n",
    "25 -          1 -      5 -    0.015358</br>\n",
    "26 -          1 -      2 -    0.012979</br>\n",
    "27 -          1 -      3 -    0.011897</br>\n",
    "28 -          1 -      1 -    0.005408</br>\n",
    "29 -          1 -     -1 -    0.003245</br>\n",
    "- Aggregate data in a Series using value_counts in pandas.\n",
    "- Aggregate data using the groupby method in pandas.\n",
    "- Create a Series in pandas.\n",
    "- Rename a Series in pandas.\n",
    "- Replace values in a column using pandas.\n",
    "- Set and reset the index of a DataFrame in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_educ = (\n",
    "    df['EDUC']\n",
    "    .groupby(df['TURNFEAR'])\n",
    "    .value_counts(normalize=True)\n",
    "    .rename('Frequency')\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"df_educ type:\", type(df_educ))\n",
    "print(\"df_educ shape:\", df_educ.shape)\n",
    "df_educ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.16:** Using seaborn, create a side-by-side bar chart of df_educ. Set hue to \"TURNFEAR\", and make sure that the education categories are in the correct order along the x-axis. Label to the x-axis \"Education Level\", the y-axis \"Frequency (%)\", and use the title \"Educational Attainment: Credit Fearful vs. Non-fearful\".\n",
    "\n",
    " - Create a bar chart using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart of `df_educ`\n",
    "sns.barplot(\n",
    "    x='EDUC',\n",
    "    y='Frequency',\n",
    "    hue='TURNFEAR',\n",
    "    data=df_educ\n",
    ")\n",
    "plt.xlabel(\"Education Level\")\n",
    "plt.ylabel(\"Frequency (%)\")\n",
    "plt.title(\"Educational Attainment: Credit Fearful vs. Non-fearful\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.17:** Use df to make a scatter plot showing the relationship between DEBT and ASSET.\n",
    "\n",
    "- Create a scatter plot with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of ASSET vs DEBT, df\n",
    "df.plot.scatter(x='DEBT', y='ASSET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.18:** Use df_fear to make a scatter plot showing the relationship between DEBT and ASSET.\n",
    "\n",
    "- Create a scatter plot with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of ASSET vs DEBT, df_fear\n",
    "df_fear.plot.scatter(x='DEBT', y='ASSET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see relationship in our df_fear graph is flatter than the one in our df graph, but they clearly are different.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let's end with the most striking difference from our matrices, and make some scatter plots showing the difference between HOUSES and DEBT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.19:** Use df to make a scatter plot showing the relationship between HOUSES and DEBT.\n",
    "\n",
    "- Create a scatter plot with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of HOUSES vs DEBT, df\n",
    "df.plot.scatter(x='DEBT', y='HOUSES');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.1.20:** Use df_fear to make a scatter plot showing the relationship between HOUSES and DEBT.\n",
    "\n",
    "- Create a scatter plot with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of HOUSES vs DEBT, df_fear\n",
    "df_fear.plot.scatter(x='DEBT', y='HOUSES');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers make it a little difficult to see the difference between these two plots, but the relationship is clear enough: our df_fear graph shows an almost perfect linear relationship, while our df graph shows something a little more muddled. You might also notice that the datapoints on the df_fear graph form several little groups. Those are called \"clusters,\" and we'll be talking more about how to analyze clustered data in the next lesson."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
