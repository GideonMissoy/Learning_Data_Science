{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract, Transform, Load\n",
    "\n",
    "In the last lesson, we focused on exploratory data analysis. Specifically, we extracted information from our MongoDB database in order to describe some characteristics of the DS Lab applicant pool ‚Äî country of origin, age, and education level. In this lesson, our goal is to design our experiment, and that means we'll need to go beyond extracting information. We'll also need to make some transformations in our data and then load it back into our database.\n",
    "\n",
    "In Data Science and Data Engineering, the process of taking data from a source, changing it, and then loading it into a database is called ETL, which is short for extract, transform, load. ETL tends to be more programming-intensive than other data science tasks like visualization, so we'll also spend time in this lesson exploring Python as an object-oriented programming language. Specifically, we'll create our own Python class to contain our ETL processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from teaching_tools.ab_test.reset import Reset\n",
    "\n",
    "r = Reset()\n",
    "r.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, the first thing we're going to need to do is get access to our data.\n",
    "\n",
    "Assign the \"ds-applicants\" collection in the \"wqu-abtest\" database to the variable name ds_app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host=\"localhost\", port=27017)\n",
    "db = client['wqu-abtest']\n",
    "ds_app = db['ds-applicants']\n",
    "print(\"client:\", type(client))\n",
    "print(\"ds_app:\", type(ds_app))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract: Developing the Hypothesis\n",
    "Now that we've connected to the data, we need to pull out the information we need. One aspect of our applicant pool that we didn't explore in the last lesson is how many applicants actually complete the DS Lab admissions quiz.\n",
    "\n",
    "Use the aggregate method to calculate the number of applicants that completed and did not complete the admissions quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ds_app.aggregate(\n",
    "    [\n",
    "        {\n",
    "            '$group': {\n",
    "                '_id': \"$admissionsQuiz\",\n",
    "                'count': {'$count': {}}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "for r in result:\n",
    "    if r ['_id'] == 'incomplete':\n",
    "        incomplete = r['count']\n",
    "    else:\n",
    "        complete = r['count']\n",
    "\n",
    "print(\"Completed quiz:\", complete)\n",
    "print(\"Did not complete quiz:\", incomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "Completed quiz: 3717\n",
    "Did not complete quiz: 1308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your results from the previous task, calculate the proportion of new users who have not completed the admissions quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = complete + incomplete\n",
    "prop_incomplete = incomplete / total\n",
    "print(\n",
    "    \"Proportion of users who don't complete admissions quiz:\", round(prop_incomplete, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Proportion of users who don't complete admissions quiz: 0.26\n",
    "Now that we know that around a quarter of DS Lab applicants don't complete the admissions quiz, is there anything we can do improve the completion rate?\n",
    "\n",
    "This is a question that we asked ourselves at WQU. In fact, here's a conversation between Nicholas and Anne (Program Director at WQU) where they identify the issue, come up with a hypothesis, and then decide how they'll conduct their experiment.\n",
    "\n",
    "A hypothesis is an informed guess about what we think is going to happen in an experiment. We probably hope that whatever we're trying out is going to work, but it's important to maintain a healthy degree of skepticism. Science experiments are designed to demonstrate what does work, not what doesn't, so we always start out by assuming that whatever we're about to do won't make a difference (even if we hope it will). The idea that an experimental intervention won't change anything is called a null hypothesis ( ùêª0\n",
    " ), and every experiment either rejects the null hypothesis (meaning the intervention worked), or fails to reject the null hypothesis (meaning it didn't).\n",
    "\n",
    "The mirror image of the null hypothesis is called an alternate hypothesis ( ùêªùëé\n",
    " ), and it proceeds from the idea that whatever we're about to do actually will work. If I'm trying to figure out whether exercising is going to help me lose weight, the null hypothesis says that if I exercise, I won't lose any weight. The alternate hypothesis says that if I exercise, I will lose weight.\n",
    "\n",
    "It's important to keep both types of hypothesis in mind as you work through your experimental design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis = \"\"\"\n",
    "    There is no relationship between receiving an email and completing the admission quiz.\n",
    "    Sending an email to 'no-quiz applicants' does not increase the rate of completion.\n",
    "\"\"\"\n",
    "\n",
    "alternate_hypothesis = \"\"\"\n",
    "    There is a relationship between receiving an email and completing the admission quiz.\n",
    "    Sending an email to 'no-quiz applicants' does increase the rate of completion.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is figure out a way to filter the data so that we're only looking at students who applied on a certain date. This is a perfect chance to write a function!\n",
    "\n",
    "Create a function find_by_date that can search a collection such as \"ds-applicants\" and return all the no-quiz applicants from a specific date. Use the docstring below for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_by_date(collection, date_string):\n",
    "    \"\"\"Find records in a PyMongo Collection created on a given date.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    collection : pymongo.collection.Collection\n",
    "        Collection in which to search for documents.\n",
    "    date_string : str\n",
    "        Date to query. Format must be '%Y-%m-%d', e.g. '2022-06-28'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    observations : list\n",
    "        Result of query. List of documents (dictionaries).\n",
    "    \"\"\"\n",
    "    # Convert `date_string` to datetime object\n",
    "    start = pd.to_datetime(date_string, format='%Y-%m-%d')\n",
    "    # Offset `start` by 1 day\n",
    "    end = start + pd.DateOffset(days=1)\n",
    "    # Create PyMongo query for no-quiz applicants b/t `start` and `end`\n",
    "    query = {\"createdAt\": {\"$gte\": start, \"$lt\": end}, \"admissionsQuiz\": \"incomplete\"}\n",
    "    # Query collection, get result\n",
    "    result = collection.find(query)\n",
    "    # Convert `result` to list\n",
    "    observations = list(result)\n",
    "    # REMOVE}\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Use your find_by_date function to create a list observations with all the new users created on 2 May 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = find_by_date(collection=ds_app, date_string='2022-05-02')\n",
    "\n",
    "print(\"observations type:\", type(observations))\n",
    "print(\"observations len:\", len(observations))\n",
    "observations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "observations type: <class 'list'>\n",
    "observations len: 49\n",
    "\"\"\"\n",
    "\n",
    "{'_id': ObjectId('67da576e9452ecc8db53a31b'),\n",
    " 'createdAt': datetime.datetime(2022, 5, 2, 2, 0, 11),\n",
    " 'firstName': 'Virginia',\n",
    " 'lastName': 'Anderson',\n",
    " 'email': 'virginia.anderson18@yahow.com',\n",
    " 'birthday': datetime.datetime(1998, 5, 17, 0, 0),\n",
    " 'gender': 'female',\n",
    " 'highestDegreeEarned': \"Bachelor's degree\",\n",
    " 'countryISO2': 'SL',\n",
    " 'admissionsQuiz': 'incomplete'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform: Designing the Experiment\n",
    "Okay! Now that we've extracted the data we'll need for the experiment, it's time to get our hands dirty.\n",
    "\n",
    "The transform stage of ETL involves manipulating the data we just extracted. In this case, we're going to be figuring out which students didn't take the quiz, and assigning them to different experimental groups. To do that, we'll need to transform each document in the database by creating a new attribute for each record.\n",
    "\n",
    "Now we can split the students who didn't take the quiz into two groups: one that will receive a reminder email, and one that will not. Let's make another function that'll do that for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function assign_to_groups that takes a list of new user documents as input and adds two keys to each document. The first key should be \"inExperiment\", and its value should always be True. The second key should be \"group\", with half of the records in \"email (treatment)\" and the other half in \"no email (control)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_to_groups(observations):\n",
    "    \"\"\"Randomly assigns observations to control and treatment groups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observations : list or pymongo.cursor.Cursor\n",
    "        List of users to assign to groups.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    observations : list\n",
    "        List of documents from `observations` with two additional keys:\n",
    "        `inExperiment` and `group`.\n",
    "    \"\"\"\n",
    "    # Shuffle `observations`\n",
    "    random.seed(42)\n",
    "    random.shuffle(observations)\n",
    "    # Get index position of item at observations halfway point\n",
    "    idx = len(observations) // 2\n",
    "\n",
    "    # Assign first half of observations to control group\n",
    "    for doc in observations[:idx]:\n",
    "        doc['inExperiment'] = True\n",
    "        doc['group'] = 'no email (control)'\n",
    "\n",
    "    # Assign second half of observations to treatment group\n",
    "    for doc in observations[idx:]:\n",
    "        doc['inExperiment'] = True\n",
    "        doc['group'] = 'email (treatment)'\n",
    "    return observations\n",
    "\n",
    "\n",
    "observations_assigned = assign_to_groups(observations)\n",
    "\n",
    "print(\"observations_assigned type:\", type(observations_assigned))\n",
    "print(\"observations_assigned len:\", len(observations_assigned))\n",
    "observations_assigned[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the video, Anne said that she needs a CSV file with applicant email addresses. Let's automate that process with another function.\n",
    "\n",
    "Create a function export_email that takes a list of documents (like observations_assigned) as input, creates a DataFrame with the emails of all observations in the treatment group, and saves the DataFrame as a CSV file. Then use your function to create a CSV file in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_treatment_emails(observations_assigned, directory=\".\"):\n",
    "    \"\"\"Creates CSV file with email addresses of observations in treatment group.\n",
    "\n",
    "    CSV file name will include today's date, e.g. `'2022-06-28_ab-test.csv'`,\n",
    "    and a `'tag'` column where every row will be 'ab-test'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observations_assigned : list\n",
    "        Observations with group assignment.\n",
    "    directory : str, default='.'\n",
    "        Location for saved CSV file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Put `observations_assigned` docs into DataFrame\n",
    "    df = pd.DataFrame(observations_assigned)\n",
    "\n",
    "    # Add `\"tag\"` column\n",
    "    df['tag'] = 'ab-test'\n",
    "\n",
    "    # Create mask for treatment group only\n",
    "    mask = df['group'] == 'email (treatment)'\n",
    "    \n",
    "    # Create filename with date\n",
    "    date_string = pd.Timestamp.now().strftime(format='%Y-%m-%d')\n",
    "    filename = directory + '/' + date_string + '_ab-test.csv'\n",
    "\n",
    "    # Save DataFrame to directory (email and tag only)\n",
    "    df[mask][['email', 'tag']].to_csv(filename, index=False)\n",
    "    \n",
    "\n",
    "\n",
    "export_treatment_emails(observations_assigned=observations_assigned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load: Preparing the Data**\n",
    "\n",
    "We've extracted the data and written a bunch of functions we can use to transform the data, so it's time for the third part of this module: loading the data.\n",
    "\n",
    "We've assigned the no-quiz applicants to groups for our experiment, so we should update the records in the \"ds-applicants\" collection to reflect that assignment. Before we update all our records, let's start with just one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the first item in observations_assigned list to the variable updated_applicant. \n",
    "Then assign that applicant's ID to the variable applicant_id.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_applicant = observations_assigned[0]\n",
    "applicant_id = updated_applicant['_id']\n",
    "print(\"applicant type:\", type(updated_applicant))\n",
    "print(updated_applicant)\n",
    "print()\n",
    "print(\"applicant_id type:\", type(applicant_id))\n",
    "print(applicant_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the find_one method together with the applicant_id from the previous task to locate the original record in the \"ds-applicants\" collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find original record for `applicant_id`\n",
    "ds_app.find_one({'_id': applicant_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the update_one method to update the record with the new information in updated_applicant. Once you're done, rerun your query from the previous task to see if the record has been updated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ds_app.update_one(\n",
    "    filter={'_id': applicant_id},\n",
    "    update= {'$set': updated_applicant}\n",
    ")\n",
    "print(\"result type:\", type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we update the document, we get a result back. Before we update multiple records, let's take a moment to explore what result is ‚Äî and how it relates to object oriented programming in Python.\n",
    "\n",
    "Use the dir function to inspect result. Once you see some of the attributes, try to access them. For instance, what does the raw_result attribute tell you about the success of your record update?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access methods and attributes using `dir`\n",
    "dir(result)\n",
    "# Access `raw_result` attribute\n",
    "result.raw_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how to update a record, and we can interpret our operation results. Since we can do it for one record, we can do it for all of them! So let's update the records for all the observations in our experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function update_applicants that takes a list of document like as input, updates the corresponding documents in a collection, and returns a dictionary with the results of the update. Then use your function to update \"ds-applicants\" with observations_assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_applicants(collection, observations_assigned):\n",
    "    \"\"\"Update applicant documents in collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    collection : pymongo.collection.Collection\n",
    "        Collection in which documents will be updated.\n",
    "\n",
    "    observations_assigned : list\n",
    "        Documents that will be used to update collection\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transaction_result : dict\n",
    "        Status of update operation, including number of documents\n",
    "        and number of documents modified.\n",
    "    \"\"\"\n",
    "    # Initialize counters\n",
    "    n = 0\n",
    "    n_modified = 0\n",
    "    for  doc in observations_assigned:\n",
    "        result = ds_app.update_one(\n",
    "            filter={'_id': doc['_id']},\n",
    "            update= {'$set': doc}\n",
    "        )\n",
    "        n += result.matched_count\n",
    "        n_modified += result.modified_count\n",
    "    \n",
    "    transaction_result = {'n': n, 'nModified': n_modified}\n",
    "    \n",
    "    return transaction_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Classes: Building the Repository**\n",
    "\n",
    "We've managed to extract data from our database using our find_by_date function, transform it using our assign_to_groups function, and load it using our update_applicants function. Does that mean we're done? Not yet! There's an issue we need to address: distraction.\n",
    "\n",
    "What do we mean when we say distraction? Think about it this way: Do you need to know the exact code that makes df.describe() work? No, you just need to calculate summary statistics! Going into more details would distract you from the work you need to get done. The same is true of the tools you've created in this lesson. Others will want to use them in future experiments with worrying about your implementation. The solution is to abstract the details of your code away.\n",
    "\n",
    "To do this we're going to create a Python class. Python classes contain both information and ways to interact with that information. An example of class is a pandas DataFrame. Not only does it hold data (like the size of an apartment in Buenos Aires or the income of a household in the United States); it also provides methods for inspecting it (like DataFrame.head() or DataFrame.info()) and manipulating it (like DataFrame.sum() or DataFrame.replace()).\n",
    "\n",
    "In the case of this project, we want to create a class that will hold information about the documents we want (like the name and location of the collection) and provide tools for interacting with those documents (like the functions we've built above). Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a MongoRepository class with an __init__ method. The __init__ method should accept three arguments: client, db, and collection. Use the docstring below as a guide.\n",
    "\n",
    "Using your function as a model, create a find_by_date method for your MongoRepository class. It should take only one argument: date_string. Once you're done, test your method by extracting all the users who created account on 15 May 2022.\n",
    "\n",
    "Using your function as a model, create an update_applicants method for your MongoRepository class. It should take one argument: documents. To test your method, use the function to update the documents in observations_assigned.\n",
    "\n",
    "Create an assign_to_groups method for your MongoRepository class. Note that it should work differently than your original function. It will take one argument: date_string. It should find users from that date, assign them to groups, update the database, and return the results of the transaction. Once you're done, use your method to assign all the users who created account on 14 May 2022, to groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MongoClient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMongoRepository\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Repository class for interacting with MongoDB database.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m        All data will be extracted from and loaded to this collection.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Task 7.2.14\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m, in \u001b[0;36mMongoRepository\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Repository class for interacting with MongoDB database.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    All data will be extracted from and loaded to this collection.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Task 7.2.14\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, client\u001b[38;5;241m=\u001b[39m\u001b[43mMongoClient\u001b[49m(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27017\u001b[39m), db\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwqu-abtest\u001b[39m\u001b[38;5;124m'\u001b[39m, collection\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds-applicants\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection \u001b[38;5;241m=\u001b[39m client[db][collection]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Task 7.2.17\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MongoClient' is not defined"
     ]
    }
   ],
   "source": [
    "class MongoRepository:\n",
    "    \"\"\"Repository class for interacting with MongoDB database.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    client : `pymongo.MongoClient`\n",
    "        By default, `MongoClient(host='localhost', port=27017)`.\n",
    "    db : str\n",
    "        By default, `'wqu-abtest'`.\n",
    "    collection : str\n",
    "        By default, `'ds-applicants'`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    collection : pymongo.collection.Collection\n",
    "        All data will be extracted from and loaded to this collection.\n",
    "    \"\"\"\n",
    "\n",
    "    # Task 7.2.14\n",
    "    def __init__(self, client=MongoClient(host='localhost', port=27017), db='wqu-abtest', collection='ds-applicants'):\n",
    "        self.collection = client[db][collection]\n",
    "\n",
    "    # Task 7.2.17\n",
    "    def find_by_date(self, date_string):\n",
    "        # Convert `date_string` to datetime object\n",
    "        start = pd.to_datetime(date_string, format='%Y-%m-%d')\n",
    "        # Offset `start` by 1 day\n",
    "        end = start + pd.DateOffset(days=1)\n",
    "        # Create PyMongo query for no-quiz applicants b/t `start` and `end`\n",
    "        query = {\"createdAt\": {\"$gte\": start, \"$lt\": end}, \"admissionsQuiz\": \"incomplete\"}\n",
    "        # Query collection, get result\n",
    "        result = self.collection.find(query)\n",
    "        # Convert `result` to list\n",
    "        observations = list(result)\n",
    "        return observations\n",
    "    \n",
    "    # Task 7.2.18\n",
    "    def update_applicants(self, observations_assigned):\n",
    "        n = 0\n",
    "        n_modified = 0\n",
    "        for  doc in observations_assigned:\n",
    "            result = self.collection.update_one(\n",
    "                filter={'_id': doc['_id']},\n",
    "                update= {'$set': doc}\n",
    "            )\n",
    "            n += result.matched_count\n",
    "            n_modified += result.modified_count\n",
    "\n",
    "        transaction_result = {'n': n, 'nModified': n_modified}\n",
    "\n",
    "        return transaction_result\n",
    "    \n",
    "    # Task 7.2.19\n",
    "    def assign_to_groups(self, date_string):\n",
    "        observations = self.find_by_date(date_string)\n",
    "        \n",
    "        random.seed(42)\n",
    "        random.shuffle(observations)\n",
    "        # Get index position of item at observations halfway point\n",
    "        idx = len(observations) // 2\n",
    "\n",
    "        # Assign first half of observations to control group\n",
    "        for doc in observations[:idx]:\n",
    "            doc['inExperiment'] = True\n",
    "            doc['group'] = 'no email (control)'\n",
    "\n",
    "        # Assign second half of observations to treatment group\n",
    "        for doc in observations[idx:]:\n",
    "            doc['inExperiment'] = True\n",
    "            doc['group'] = 'email (treatment)'\n",
    "        \n",
    "        result = self.update_applicants(observations)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of your MongoRepository and assign it to the variable name repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = MongoRepository()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the collection attribute from repo, and assign it to the variable c_test. Is the c_test the correct data type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_test = repo.collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your method by extracting all the users who created account on 15 May 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_15_users = repo.find_by_date(date_string='2022-05-15')\n",
    "print(\"may_15_users type\", type(may_15_users))\n",
    "print(\"may_15_users len\", len(may_15_users))\n",
    "may_15_users[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your method, use the function to update the documents in observations_assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = repo.update_applicants(observations_assigned)\n",
    "print(\"result type:\", type(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se your method to assign all the users who created account on 14 May 2022, to groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = repo.assign_to_groups(date_string='2022-05-15')\n",
    "print(\"result type:\", type(result))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
